from utils import re
from utils import pandas as pd
from utils import numpy as np
from utils import robjects, pandas2ri,ro,localconverter
from judge_day_night import judge_day_night
from add_window_tag import add_window_tag
from calculate_diff import calculate_diff
from calculate_md_mad import md_method,mad_method
from set_data_nan import set_data_nan

def do_add_strg(self, data):
    # å®šä¹‰éœ€è¦å¤„ç†çš„å˜é‡åˆ—è¡¨
    variables = [
        ('co2_flux', 'co2_flux_filter_label', 'co2_flux_strg', 'co2_flux_add_strg'),
        ('h2o_flux', 'h2o_flux_filter_label', 'h2o_flux_strg', 'h2o_flux_add_strg'),
        ('le', 'le_filter_label', 'le_strg', 'le_add_strg'),
        ('h', 'h_filter_label', 'h_strg', 'h_add_strg')
    ]

    for _, filter_col, strg_col, result_col in variables:
        if filter_col in data.columns:
            data[filter_col] = data[filter_col].astype('float')
            if strg_col in data.columns:
                data[strg_col] = data[strg_col].astype('float')
                data[result_col] = data[filter_col] + data[strg_col]

    return data

def not_add_strg(self, data):
    # å®šä¹‰éœ€è¦å¤„ç†çš„å˜é‡åˆ—è¡¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    variables = [
        ('co2_flux_filter_label', 'co2_flux_add_strg'),
        ('h2o_flux_filter_label', 'h2o_flux_add_strg'),
        ('le_filter_label', 'le_add_strg'),
        ('h_filter_label', 'h_add_strg')
    ]

    for filter_col, result_col in variables:
        if filter_col in data.columns:
            data[filter_col] = data[filter_col].astype('float')
            data[result_col] = data[filter_col]

    return data

def copy_flux_columns_without_qc_filter(data: pd.DataFrame):
    """ç›´æ¥å¤åˆ¶é€šé‡åˆ—è€Œä¸è¿›è¡ŒQCæ ‡è®°è¿‡æ»¤"""
    data['co2_flux_filter_label'] = data['co2_flux']
    data['h2o_flux_filter_label'] = data['h2o_flux']
    data['le_filter_label'] = data['le']
    data['h_filter_label'] = data['h']

    data['qc_co2_flux'] = data['qc_co2_flux'].astype('float')
    data['qc_h2o_flux'] = data['qc_h2o_flux'].astype('float')
    data['qc_le'] = data['qc_le'].astype('float')
    data['qc_h'] = data['qc_h'].astype('float')
    return data

def handle_campbell_special_case(data: pd.DataFrame):
    """å¤„ç†Campbellç«™ç‚¹ç‰¹æ®Šæƒ…å†µ(ç¼ºå°‘æŸäº›é€šé‡æ•°æ®)"""
    data['co2_flux_filter_label'] = data['co2_flux']

    # å…«è¾¾å²­ã€å¥¥æ£®æ²¡æœ‰h2o_fluxã€qc_co2_fluxã€qc_h2o_flux
    data['h2o_flux'] = (data['le'].astype(float)) / 2450 / 18 * 1000
    data['h2o_flux_filter_label'] = data['h2o_flux']

    data['le_filter_label'] = data['le']
    data['h_filter_label'] = data['h']

    return data

def filter_flux_by_qc_flags(data, excluded_qc_flags):
    """æ ¹æ®QCæ ‡è®°è¿‡æ»¤é€šé‡æ•°æ®"""
    data['co2_flux_filter_label'] = data['co2_flux']
    data['h2o_flux_filter_label'] = data['h2o_flux']
    data['le_filter_label'] = data['le']
    data['h_filter_label'] = data['h']
    try:
        data.loc[data['qc_co2_flux'].isin(excluded_qc_flags), 'co2_flux_filter_label'] = np.NAN
        data.loc[data['qc_h2o_flux'].isin(excluded_qc_flags), 'h2o_flux_filter_label'] = np.NAN
        data.loc[data['qc_le'].isin(excluded_qc_flags), 'le_filter_label'] = np.NAN
        data.loc[data['qc_h'].isin(excluded_qc_flags), 'h_filter_label'] = np.NAN

        data['qc_co2_flux'] = data['qc_co2_flux'].astype('float')
        data['qc_h2o_flux'] = data['qc_h2o_flux'].astype('float')
        data['qc_le'] = data['qc_le'].astype('float')
        data['qc_h'] = data['qc_h'].astype('float')

        return data
    except Exception as e:
        print(e)

def threshold_limit(data, qc_indicators, data_type):
    """ é˜ˆå€¼è¿‡æ»¤

    Args:
        data (dataframe): data
        qc_indicators (list): all indicators

    Returns:
        dataframe: result
    """
    if data_type == 'flux':
        try:
            # ç‰¹æ®Šå˜é‡ä¸å…¶å¯¹åº”çš„ add_strg å’Œ threshold_limit åˆ—åçš„æ˜ å°„
            special_vars = {
                'co2_flux': {'add_strg': 'co2_flux_add_strg', 'threshold': 'co2_flux_threshold_limit'},
                'h2o_flux': {'add_strg': 'h2o_flux_add_strg', 'threshold': 'h2o_flux_threshold_limit'},
                'le': {'add_strg': 'le_add_strg', 'threshold': 'le_threshold_limit'},
                'h': {'add_strg': 'h_add_strg', 'threshold': 'h_threshold_limit'},
            }
             # åˆ›å»ºä¸€ä¸ªå­—å…¸æ¥å¿«é€ŸæŸ¥æ‰¾ qc_indicators ä¸­çš„å€¼
            qc_dict = {item['code']: {'lower': float(item['qc_lower_limit']), 'upper': float(item['qc_upper_limit'])} for item in qc_indicators}
            for col in data.columns:
                if col in qc_dict:
                    limits=qc_dict[col]
                    if col in special_vars:
                        # å¯¹ç‰¹æ®Šå˜é‡å¤„ç†
                        add_strg_col=special_vars[col]['add_strg']
                        threshold_col=special_vars[col]['threshold']
                        if add_strg_col in data.columns:
                            condition=(data[add_strg_col]<limits['lower'])|(data[add_strg_col]>limits['upper'])
                            data[threshold_col]=data[add_strg_col]
                            data.loc[condition, threshold_col]=np.NAN
                    else:
                        # å¯¹å…¶ä»–å˜é‡å¤„ç†
                        threshold_col=col + "_threshold_limit"
                        condition=(data[col]<limits['lower'])|(data[col]>limits['upper'])
                        data[threshold_col]=data[col]
                        data.loc[condition, threshold_col]=np.NAN
            return data
        except Exception as e:
            print(e)
    else:
        # å…ˆè½¬æˆfloat
        for i in data.columns:
            if i != 'record_time':
                print(data[i])
                data[i] = data[i].astype('float')
        try:
            for i in qc_indicators:
                for j in data.columns:
                    if data_type == 'aqi':
                        if re.sub(r"\W", "_", i["en_name"]).lower() == j:
                            condition = (data[j] < float(i['qc_lower_limit'])) | (data[j] > float(i['qc_upper_limit']))
                            data[j + "_threshold_limit"] = data[j]
                            data.loc[condition, j + "_threshold_limit"] = np.NAN
                    else:
                        if i['code'] == j:
                            condition = (data[j] < float(i['qc_lower_limit'])) | (data[j] > float(i['qc_upper_limit']))
                            data[j + "_threshold_limit"] = data[j]
                            data.loc[condition, j + "_threshold_limit"] = np.NAN
        except Exception as e:
            print(e)
        if data_type == 'sapflow':
            for i in qc_indicators:
                for j in data.columns:
                    # å¦‚æœåˆ—åä»¥ tc_dtca_ å¼€å¤´ï¼Œæ‰§è¡Œ del_abnormal_data å‡½æ•°
                    if i['code'] == j and j.startswith('tc_dtca_'):
                        data = del_abnormal_data_sapflow(data, ta_name="ta_1_2_1_threshold_limit", daca_name=j + "_threshold_limit")
            # èŒæµé€Ÿç‡ ç”¨5å€æ ‡å‡†å·®å†ç­›é€‰ä¸€éæ•°æ®
            data.to_csv('weishanzhuang.csv',index=False)
            print(data.columns)
            print(data.dtypes)
            data = standard_deviation_limit(data)
        elif data_type == 'aqi':
            # è¡¥åŠç‚¹æ•°æ®å°†ç”¨å‰åæ•´ç‚¹æ•°æ®çš„å‡å€¼æ¥æ’è¡¥ï¼Œè‹¥å‰åè‡³å°‘æœ‰ä¸€ä¸ªæ˜¯NaNé‚£ä¹ˆè¿™ä¸ªåŠç‚¹çš„æ•°æ®å°±æ˜¯NaN
            # å°†æ—¶é—´è®¾ä¸ºindex
            data = data.set_index(pd.to_datetime(data['record_time'])).drop(
                'record_time', axis=1)
            # è¡¥å…¨æ—¶é—´åºåˆ— åŠç‚¹æ•°æ®ç½®ä¸ºNaN
            data = data.resample('30min').mean()
            # å°†åŠç‚¹çš„å€¼ç½®ä¸ºå‰åæ•´ç‚¹æ•°æ®çš„å‡å€¼
            for i in range(data.shape[0]):
                if data.iloc[i].name.minute == 30:
                    data.iloc[i] = (data.iloc[i - 1] + data.iloc[i + 1]) / 2
            data = data.reset_index()
        return data
    
def del_abnormal_data_sapflow(raw_data, ta_name="ta_1_2_1_threshold_limit", daca_name="tc_dtca_1__threshold_limit"):
    df = raw_data.copy()
    df[daca_name + "_old"] = df[daca_name]

    if ta_name in df.columns and 'record_time' in df.columns:
        df['record_time'] = pd.to_datetime(df['record_time'])
        df['date'] = df['record_time'].dt.date

        # è®¡ç®—æ¯æ—¥çš„å¹³å‡æ¸©åº¦
        daily_avg_temp = df.groupby('date')[ta_name].mean()

        daily_df = pd.DataFrame({
            'date': daily_avg_temp.index,
            'day_avg_tair': daily_avg_temp.values
        })

        # ä»¥å¤©ä¸ºå•ä½å¯¹ 'ta' åˆ—è¿›è¡Œæ»šåŠ¨å¹³å‡ï¼Œå¹¶ç¡®ä¿çª—å£åŒ…å«3å¤©çš„æ•°æ®
        daily_df['ta_three_avg'] = daily_df['day_avg_tair'].rolling(window=3, min_periods=3, center=True).mean()

        # å‰ å’Œ å èµ‹å€¼æœ€è¿‘çš„å€¼
        first_non_nan = daily_df['ta_three_avg'].first_valid_index()
        last_non_nan = daily_df['ta_three_avg'].last_valid_index()
        if last_non_nan is not None:
            last_non_nan_value = daily_df.at[last_non_nan, 'ta_three_avg']
        else:
            last_non_nan_value = pd.NA  # å¦‚æœæ•´ä¸ªåˆ—éƒ½æ˜¯ NaNï¼Œåˆ™è¿™é‡Œä¹Ÿæ˜¯ NaN

        # ç”¨ç¬¬ä¸€ä¸ªéNaNå€¼å¡«å……å‰é¢çš„NaN
        daily_df['ta_three_avg'] = daily_df['ta_three_avg'].fillna(method='bfill',
                                                                   limit=daily_df.index.get_loc(first_non_nan))

        # ç”¨æœ€åä¸€ä¸ªéNaNå€¼å¡«å……åé¢çš„NaN
        daily_df['ta_three_avg'] = daily_df['ta_three_avg'].fillna(last_non_nan_value)

        # æ·»åŠ æ˜¯å¦æ˜¯ç”Ÿé•¿å­£çš„åˆ—ï¼ˆæ¸©åº¦æ˜¯å¦å°äº5ï¼‰
        daily_df['is_grow_season'] = (daily_df['ta_three_avg'] >= 5).astype(int)

        df = df.merge(daily_df[['date', 'is_grow_season']], on='date', how='left')
        del df['date']

        # åœ¨ç”Ÿé•¿å­£å‰”é™¤ä¸åœ¨ [3, 12] èŒƒå›´å†…çš„æ•°æ®
        condition = (df['is_grow_season'] == 1) & ((df[daca_name] < 3) | (df[daca_name] > 12))
        df.loc[condition, daca_name] = pd.NA

        # åˆ é™¤ 'is_grow_season' åˆ—
        del df['is_grow_season']

    return df

def standard_deviation_limit(data):
    """sapflow 5 times Standard deviation limit
        æ»‘åŠ¨çª—å£æ˜¯480 ç„¶åæ»‘åŠ¨èŒƒå›´å¯ä»¥æ»‘ä¸€å¤©96
    Args:
        data (df): the pandas dataframe
        å®Œäº† ä¸€ä¸ªæœˆåçœ‹ä¸æ‡‚è‡ªå·±å½“åˆå†™çš„æ˜¯å•¥äº†ğŸ˜­
        å…³é”®ä»£ç è¿˜æ˜¯è¦å†™æ³¨é‡Š....
    """
    sapflow_data = pd.DataFrame()
    #sapflow_data['record_time'] = data['record_time']
    for i in data.columns.tolist():
        if i.split("_")[-1] == 'limit':
            sapflow_data[i+'_std'] = data[i]
    index = 0
    while (index < sapflow_data.shape[0]):
        if (index + 479) > (sapflow_data.shape[0]):
            break

            # æ‰“å°å½“å‰çš„ index å€¼
        print(f"Index: {index}")

        # è®¡ç®—å½“å‰çª—å£å†…çš„æ•°æ®çš„å‡å€¼å’Œæ ‡å‡†å·®
        window_mean = sapflow_data.iloc[index:index + 480].mean()
        window_std = sapflow_data.iloc[index:index + 480].std()

        print(f"window_mean-----{window_mean}")
        print(f"window_std------{window_std}")
        # æ£€æŸ¥å‡å€¼æ˜¯å¦å…¨æ˜¯ NaN
        if window_mean.isna().all():
            print(f"Skipping index {index} due to all NaN mean values.")
            index += 96
            continue

        sapflow_data[(sapflow_data.iloc[index:index + 480] >
              (sapflow_data.iloc[index:index + 480].mean() + sapflow_data.iloc[index:index + 480].std())) |
             (sapflow_data.iloc[index:index + 480] < (sapflow_data.iloc[index:index + 480].mean() -
                                      sapflow_data.iloc[index:index + 480].std()))] = np.nan
        index += 96
    sapflow_data['record_time']=data['record_time']
    full_data = pd.merge(data, sapflow_data, how='outer', on='record_time')
    # std ç­›é€‰åï¼Œsapflowåªä¿ç•™00å’Œ30åˆ†çš„æ•°æ®ï¼Œ15çš„å’Œ45çš„å°±ä¸è¦äº†ï¼Œæ•°æ®äº§å“æš‚æ—¶éƒ½æ˜¯30åˆ†é’Ÿçš„
    full_data['record_time'] = pd.to_datetime(full_data['record_time'])
    new_data = full_data.drop(full_data[full_data['record_time'].apply(
        lambda x: x.minute == 15 or x.minute == 45)].index)
    return new_data


def gap_fill_par(file_name,longitude,latitude,timezone,data):
    """
    æ’è¡¥parå…‰åˆæœ‰æ•ˆè¾å°„
    Args:
        file_name (str): æ–‡ä»¶å
        longitude (float): ç»åº¦
        latitude (float): çº¬åº¦
        timezone (int): æ—¶åŒº
        data (pd.DataFrame): æ•°æ®
    """
    # å°†æ•°æ®è½¬åŒ–æˆRè¯­è¨€çš„ç±»å‹
    data['record_time'] = pd.to_datetime(data['record_time'])
    data=data.rename(columns={"record_time": "DateTime"})
    data['rH'] = data['rh_threshold_limit'] if 'rh_threshold_limit' in data.columns else None
    data['Rg'] = data['rg_1_1_2_threshold_limit'] if 'rg_1_1_2_threshold_limit' in data.columns else None
    data['Tair'] = data['ta_1_2_1_threshold_limit'] if 'ta_1_2_1_threshold_limit' in data.columns else None
    # vpd pa to hpa
    data['VPD'] = data['vpd_threshold_limit'] * 0.01 if 'vpd_threshold_limit' in data.columns else None
    data['Par'] = data['ppfd_1_1_1_threshold_limit'] if 'ppfd_1_1_1_threshold_limit' in data.columns else None
 
    r_filename=robjects.StrVector([file_name])
    r_longitude=robjects.FloatVector([longitude])
    r_latitude=robjects.FloatVector([latitude])
    r_timezone=robjects.IntVector([timezone])
    data_r=pandas2ri.py2ri(data)
    result_data=robjects.r['r_gap_fill_par'](r_filename,r_longitude,r_latitude,r_timezone,data_r)

    with localconverter(ro.default_converter+pandas2ri.converter):
        result_data=ro.conversion.rpy2py(result_data)
    result_data.rename(columns={"DateTime":"record_time"},inplace=True)
    result_data["record_time"]=result_data["record_time"].dt.tz_localize(None)
    result_data.set_index("record_time")
    result_data.drop(["rH", "Rg", "Tair", "VPD", "Par"], axis=1, inplace=True)
    return result_data



def despiking_data(data, despiking_z):
    """
    Parameters:
    ----------
        data : dataframe
            æ’è¡¥åçš„paræ•°æ®
        despiking_z : int 
            z

    Returns:
        data: df
            å»å³°å€¼åçš„æ•°æ®
    """

    # 1.åˆ¤æ–­ç™½å¤©é»‘å¤œï¼Œè€ç‰ˆä»£ç æœ‰ä¸¤ä¸ªåˆ¤æ–­æ–¹å¼ï¼Œä½†è¿™è¾¹ä¼šç›´æ¥åœ¨ä¸€ä¸ªå€¼ä¸­ç›´æ¥åˆ¤æ–­
    # å¦‚æœæ€»è¾å°„ global_radiation(rg_1_1_2) > 20 è¿™ä¸ªå€¼æ²¡æœ‰ï¼Œå°±ç”¨ å…¥å°„å…‰åˆæœ‰æ•ˆè¾å°„(ppfd_1_1_1 >5)
    # å¦‚æœä¸¤ä¸ªéƒ½æ²¡æœ‰ï¼Œåªèƒ½ç”¨æœ€æ­»æ¿çš„ daytime(ç™½å¤©1æ™šä¸Š0)

    data['co2_despiking'] = data['co2_flux_threshold_limit']
    data['h2o_despiking'] = data['h2o_flux_threshold_limit']
    data['le_despiking'] = data['le_threshold_limit']
    data['h_despiking'] = data['h_threshold_limit']

    data = judge_day_night(data)

    # 2.åŠ ä¸Šwindowæ ‡ç­¾
    # è¿™é‡Œæ³¨æ„window dataæ˜¯ flux å€¼ä¸ä¸ºNaNçš„æ¡ç›®ï¼ï¼Œå…ˆgetåˆ°è¿™äº›æ¡ç›®å»è®¾ç½®è¿™ä¸ªmadå’Œmdï¼Œ
    # å†åœ¨åŸå§‹æ¡ç›®ä¸­æ ¹æ®è¿™ä¸ªæ¥è®¾nanï¼Œæœ€åå­˜ä¸‹æ¥çš„å°±æ˜¯æ—¶é—´é½å…¨è€Œä¸”å»æ‰è¿™äº›æ¡ä»¶çš„æ•°æ®å•¦

    co2_window_data = data[data['co2_despiking'].notnull()].reset_index(drop=True)
    h2o_window_data = data[data['h2o_despiking'].notnull()].reset_index(drop=True)
    le_window_data = data[data['le_despiking'].notnull()].reset_index(drop=True)
    h_window_data = data[data['h_despiking'].notnull()].reset_index(drop=True)

    co2_window_data, co2_window_size, co2_window_nums = add_window_tag(co2_window_data)
    h2o_window_data, h2o_window_size, h2o_window_nums = add_window_tag(h2o_window_data)
    le_window_data, le_window_size, le_window_nums = add_window_tag(le_window_data)
    h_window_data, h_window_size, h_window_nums = add_window_tag(h_window_data)

    # 3.æ ¹æ®æ¯ä¸ªwindowçš„å€¼è®¡ç®—å¯¹åº”çš„MADå’ŒMd
    variables_config = {
        'co2': {'data': co2_window_data, 'window_nums': co2_window_nums},
        'h2o': {'data': h2o_window_data, 'window_nums': h2o_window_nums},
        'le': {'data': le_window_data, 'window_nums': le_window_nums},
        'h': {'data': h_window_data, 'window_nums': h_window_nums}
    }
    for var_name,window_data in variables_config.items():
        window_nums=window_data['window_nums']
        data = process_variable_despiking(data, window_data['data'], var_name, window_nums, despiking_z)
    return data

def process_variable_despiking(data, window_data, var_name, window_nums, despiking_z):
    """
    å¯¹æŒ‡å®šå˜é‡è¿›è¡Œå»å°–å³°å¤„ç†
    
    å‚æ•°:
    data: ä¸»æ•°æ®é›†
    window_data: æŒ‰çª—å£åˆ’åˆ†çš„æ•°æ®
    var_name: å˜é‡åç§°ï¼ˆå¦‚'co2', 'h2o'ç­‰ï¼‰
    window_nums: çª—å£æ•°é‡
    despiking_z: å»å°–å³°çš„zç³»æ•°
    
    è¿”å›:
    å¤„ç†åçš„ä¸»æ•°æ®é›†
    """
    diff_col = f"{var_name}_diff"
    md_col = f"{var_name}_Md"
    mad_col = f"{var_name}_MAD"
    despiking_col = f"{var_name}_despiking"
    
    # é¢„å…ˆåˆ›å»ºdiffåˆ—ï¼Œé¿å…é‡å¤åˆ›å»º
    if diff_col not in window_data.columns:
        window_data[diff_col] = np.nan
    
    for i in range(window_nums):
        # åŸºäºçª—å£IDå’Œç™½å¤©/é»‘å¤œæ ‡å¿—ç­›é€‰æ•°æ®
        window_condition = window_data['windowID'] == i
        day_condition = window_condition & (window_data['is_day_night'] == 1)
        night_condition = window_condition & (window_data['is_day_night'] == 0)
        
        # ä¸€æ¬¡æ€§è·å–ç™½å¤©å’Œå¤œæ™šæ•°æ®ï¼Œé¿å…é‡å¤ç­›é€‰
        window_data_D = window_data[day_condition]
        window_data_N = window_data[night_condition]
        
        # è®¡ç®—ç™½å¤©å’Œå¤œæ™šçš„å·®åˆ†
        if not window_data_D.empty:
            temp_diff = calculate_diff(window_data_D, despiking_col)
            window_data.loc[temp_diff.index, diff_col] = temp_diff
        
        if not window_data_N.empty:
            temp_diff = calculate_diff(window_data_N, despiking_col)
            window_data.loc[temp_diff.index, diff_col] = temp_diff
        
        # é‡æ–°è·å–æ›´æ–°åçš„ç™½å¤©å’Œå¤œæ™šæ•°æ®
        window_data_D = window_data[day_condition]
        window_data_N = window_data[night_condition]
        
        # è®¡ç®—MDå’ŒMAD
        window_data = md_method(window_data_D, window_data_N, window_data, var_name)
        
        # é‡æ–°è·å–æ›´æ–°åçš„ç™½å¤©å’Œå¤œæ™šæ•°æ®
        window_data_D = window_data[day_condition]
        window_data_N = window_data[night_condition]
        window_data = mad_method(window_data_D, window_data_N, window_data, var_name)
        
        # è®¡ç®—å¹¶æ ‡è®°å³°å€¼
        di_low_range = window_data[md_col] - (despiking_z * window_data[mad_col]) / 0.6745
        di_high_range = window_data[md_col] + (despiking_z * window_data[mad_col]) / 0.6745
        
        # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ£€æµ‹æ¡ä»¶
        condition = (window_data[diff_col] < di_low_range) | (window_data[diff_col] > di_high_range)
        condition = condition & window_condition  # åªè€ƒè™‘å½“å‰çª—å£
        
        if condition.any():
            # åªå¤„ç†ç¬¦åˆæ¡ä»¶çš„è®°å½•
            spike_times = window_data.loc[condition, 'record_time'].tolist()
            data_condition = data['record_time'].isin(spike_times)
            data = set_data_nan(data, data_condition, despiking_col)
    
    return data




def del_abnormal_data(raw_data, ta_name="ta_1_2_1_threshold_limit", par_name="ppfd_1_1_1_threshold_limit",
                      nee_name="co2_flux_threshold_limit"):

    df = judge_day_night(data=raw_data, ppfd_1_1_1=par_name)
    # æ–°çš„ä¸€è¡Œ
    df[nee_name + "_old"] = df[nee_name]
    if ta_name in df.columns and 'record_time' in df.columns:
        df['record_time'] = pd.to_datetime(df['record_time'])

        df['date'] = df['record_time'].dt.date
        # è®¡ç®—æ¯æ—¥çš„å¹³å‡æ¸©åº¦
        daily_avg_temp = df.groupby('date')[ta_name].mean()

        daily_df = pd.DataFrame({
            'date': daily_avg_temp.index,
            'day_avg_tair': daily_avg_temp.values
        })

        # ä»¥å¤©ä¸ºå•ä½å¯¹ 'ta' åˆ—è¿›è¡Œæ»šåŠ¨å¹³å‡ï¼Œå¹¶ç¡®ä¿çª—å£åŒ…å«3å¤©çš„æ•°æ®
        daily_df['ta_three_avg'] = daily_df['day_avg_tair'].rolling(window=3, min_periods=3, center=True).mean()
        # å‰ å’Œ å èµ‹å€¼æœ€è¿‘çš„å€¼
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéNaNå€¼çš„ä½ç½®
        first_non_nan = daily_df['ta_three_avg'].first_valid_index()

        # æ‰¾åˆ°æœ€åä¸€ä¸ªéNaNå€¼
        last_non_nan = daily_df['ta_three_avg'].last_valid_index()
        if last_non_nan is not None:
            last_non_nan_value = daily_df.at[last_non_nan, 'ta_three_avg']
        else:
            last_non_nan_value = pd.NA  # å¦‚æœæ•´ä¸ªåˆ—éƒ½æ˜¯ NaNï¼Œåˆ™è¿™é‡Œä¹Ÿæ˜¯ NaN

        # ç”¨ç¬¬ä¸€ä¸ªéNaNå€¼å¡«å……å‰é¢çš„NaN
        daily_df['ta_three_avg'] = daily_df['ta_three_avg'].fillna(method='bfill',
                                                       limit=daily_df.index.get_loc(first_non_nan))

        # ç”¨æœ€åä¸€ä¸ªéNaNå€¼å¡«å……åé¢çš„NaN
        daily_df['ta_three_avg'] = daily_df['ta_three_avg'].fillna(last_non_nan_value)

        # æ·»åŠ æ˜¯å¦æ˜¯ç”Ÿé•¿å­£çš„åˆ—ï¼ˆæ¸©åº¦æ˜¯å¦å°äº5ï¼‰
        daily_df['is_grow_season'] = 0
        daily_df.loc[daily_df['ta_three_avg'] >= 5, 'is_grow_season'] = 1
        df = df.merge(daily_df[['date', 'is_grow_season']].rename(columns={'is_grow_season': 'is_grow_season'}), on='date',how='left')

        del df['date']

        codition =(((df['is_day_night'] == 1) & (-1 >= df[nee_name]) & (df[nee_name] >= 1) & (df['is_grow_season'] == 0)) | 
                   ((df['is_day_night'] == 0) & (df[nee_name] < -0.2) & (df['is_grow_season'] == 0)))
        df.loc[codition, nee_name] = pd.NA

        # è¾“å‡ºç»“æœï¼ŒæŸ¥çœ‹ DataFrame
        # print(df)
        del df['is_grow_season']
        return df
    return df
